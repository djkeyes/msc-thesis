\chapter{Abstract}

In any camera motion estimation pipeline, the problem of relocalization---determining where a camera is located in a previously constructed map---must be addressed to recover from tracking loss, minimize drift, and remain reliable over time. Whereas traditionally these maps have contained only a very sparse cloud of points, recent developments in visual odometry have shown that it is possible to generate a relatively dense point cloud while tracking camera motion. In this work, we leverage this rich geometric information to perform camera relocalization. We adopt approaches that were previously viable only with dedicated depth-sensing hardware; we analyze our results on two well-known relocalization benchmarks; and we analyze failure cases.
